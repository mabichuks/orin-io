{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820473cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, Document, StorageContext\n",
    "from llama_index.core import Settings\n",
    "from constants import embed_model, llm_model, INDEX_PERSIST_PATH, ENHANCED_RAG_TEMPLATE, CISA_ICS_RSS_URL, MAX_ADVISORIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e49d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cisa_advisories() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch ICS security advisories from CISA RSS feed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse RSS feed\n",
    "        feed = feedparser.parse(CISA_ICS_RSS_URL)\n",
    "        \n",
    "        advisories = []\n",
    "        for i, entry in enumerate(feed.entries[:MAX_ADVISORIES]):\n",
    "            advisory = {\n",
    "                'id': entry.get('id', f'advisory_{i}'),\n",
    "                'title': entry.get('title', 'No Title'),\n",
    "                'summary': entry.get('summary', 'No Summary'),\n",
    "                'link': entry.get('link', ''),\n",
    "                'published': entry.get('published', str(datetime.now())),\n",
    "                'content': entry.get('summary', '') + ' ' + entry.get('title', '')\n",
    "            }\n",
    "            advisories.append(advisory)\n",
    "            print(f\"Fetched advisory {i+1}: {advisory['title']}\")\n",
    "            \n",
    "        return advisories\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching CISA advisories: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a03abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mitre_embeddings(embed_model):\n",
    "    \"\"\"\n",
    "    Create embeddings for all MITRE ATT&CK techniques\n",
    "    \"\"\"\n",
    "    mitre_embeddings = {}\n",
    "    with open(\"assets/mitre-ics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        mitre_data = json.load(f)\n",
    "\n",
    "    for item in mitre_data:\n",
    "        # Create searchable text combining name and description\n",
    "        technique_text = f\"{item['name']} {item['description']} {item['tactics']}\"\n",
    "        technique_id = item['Id']\n",
    "        # Generate embedding\n",
    "        embedding = embed_model.get_text_embedding(technique_text)\n",
    "        mitre_embeddings[technique_id] = {\n",
    "            'embedding': embedding,\n",
    "            'text': technique_text,\n",
    "            'details': item\n",
    "        }\n",
    "        print(f\"Generated embedding for {technique_id}\")\n",
    "    \n",
    "    return mitre_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901142bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_mitre_techniques(advisory_content: str, mitre_embeddings: Dict, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Find top-k most similar MITRE ATT&CK techniques using embedding similarity\n",
    "    \"\"\"\n",
    "    # Generate embedding for advisory content\n",
    "    advisory_embedding = embed_model.get_text_embedding(advisory_content)\n",
    "    \n",
    "    # Calculate cosine similarity with all MITRE techniques\n",
    "    similarities = []\n",
    "    \n",
    "    for technique_id, data in mitre_embeddings.items():\n",
    "        mitre_emb = np.array(data['embedding'])\n",
    "        advisory_emb = np.array(advisory_embedding)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        cosine_sim = np.dot(mitre_emb, advisory_emb) / (\n",
    "            np.linalg.norm(mitre_emb) * np.linalg.norm(advisory_emb)\n",
    "        )\n",
    "        \n",
    "        similarities.append({\n",
    "            'technique_id': technique_id,\n",
    "            'similarity': float(cosine_sim),\n",
    "            'details': data['details']\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity and return top-k\n",
    "    similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a7bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_mitre_attack(advisory_content: str, mitre_embeddings=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Enhanced MITRE ATT&CK mapping using two-stage approach:\n",
    "    1. Embedding-based similarity filtering\n",
    "    2. LLM-based refined analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Stage 1: Use embeddings to find top candidate techniques\n",
    "        candidate_techniques = None\n",
    "        if mitre_embeddings:\n",
    "            print(\"Stage 1: Finding similar MITRE techniques using embeddings...\")\n",
    "            candidates = find_similar_mitre_techniques(\n",
    "                advisory_content, mitre_embeddings, top_k=5\n",
    "            )\n",
    "            \n",
    "            # Prepare candidate techniques for LLM analysis\n",
    "            candidate_techniques = {\n",
    "                cand['technique_id']: cand['details'] \n",
    "                for cand in candidates\n",
    "            }\n",
    "            \n",
    "            print(f\"Top candidates: {list(candidate_techniques.keys())}\")\n",
    "        \n",
    "        # Stage 2: Use LLM for refined mapping on filtered candidates\n",
    "        print(\"Stage 2: LLM-based refined analysis...\")\n",
    "\n",
    "        with open(\"assets/mitre-ics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            mitre_data = json.load(f)\n",
    "        \n",
    "        # Use candidate techniques if available, otherwise full set\n",
    "        techniques_to_analyze = candidate_techniques if candidate_techniques else mitre_data\n",
    "        \n",
    "        # Enhanced prompt for refined analysis\n",
    "        refined_prompt = REFINED_MITRE_PROMPT_TEMPLATE.format(\n",
    "            advisory_content=advisory_content,\n",
    "            techniques_to_analyze=json.dumps(techniques_to_analyze, indent=2)\n",
    "        )\n",
    "        \n",
    "        response = llm_model.complete(refined_prompt)\n",
    "        print(f\"LLM response: {response.text}\")\n",
    "\n",
    "        mapping = json.loads(response.text)\n",
    "        print(f\"Final mapping: {mapping}\")\n",
    "        return mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in map_to_mitre_attack: {e}\")\n",
    "        return {\"mapped_techniques\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b34434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_store_index(advisories, mitre_embeddings):\n",
    "    \"\"\"\n",
    "    Create vector store index and persist to storage\n",
    "    \"\"\"\n",
    "    print(\"Processing advisories and mapping to MITRE ATT&CK...\")\n",
    "    documents = []\n",
    "    processed_advisories = []\n",
    "    \n",
    "    for advisory in advisories:\n",
    "        # Map to MITRE ATT&CK techniques\n",
    "        mitre_mapping = map_to_mitre_attack(\n",
    "            advisory['content'], \n",
    "            mitre_embeddings,\n",
    "        )\n",
    "        \n",
    "        # Create enhanced content with MITRE mapping\n",
    "        enhanced_content = f\"\"\"\n",
    "        Title: {advisory['title']}\n",
    "        Summary: {advisory['summary']}\n",
    "        Published: {advisory['published']}\n",
    "        Link: {advisory['link']}\n",
    "        \n",
    "        MITRE ATT&CK Mapping:\n",
    "        Techniques: {', '.join(mitre_mapping.get('mapped_techniques', []))}\n",
    "        \n",
    "        Full Content: {advisory['content']}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create document with metadata\n",
    "        doc = Document(\n",
    "            text=enhanced_content,\n",
    "            metadata={\n",
    "                'id': advisory['id'],\n",
    "                'title': advisory['title'],\n",
    "                'published': advisory['published'],\n",
    "                'link': advisory['link'],\n",
    "                'mitre_techniques': mitre_mapping.get('mapped_techniques', []),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        documents.append(doc)\n",
    "        \n",
    "        # Store processed advisory data\n",
    "        advisory_data = advisory.copy()\n",
    "        advisory_data['mitre_mapping'] = mitre_mapping\n",
    "        processed_advisories.append(advisory_data)\n",
    "    \n",
    "    print(\"Creating vector store index...\")\n",
    "    # Set up LlamaIndex settings\n",
    "    Settings.llm = llm_model\n",
    "    Settings.embed_model = embed_model\n",
    "    \n",
    "    # Create index\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    \n",
    "    # Persist the index\n",
    "    print(\"Persisting index to storage...\")\n",
    "    index.storage_context.persist(persist_dir=INDEX_PERSIST_PATH)\n",
    "    \n",
    "    # Save advisory metadata\n",
    "    metadata_path = os.path.join(INDEX_PERSIST_PATH, \"advisories_metadata.json\")\n",
    "    os.makedirs(INDEX_PERSIST_PATH, exist_ok=True)\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(processed_advisories, f, indent=2)\n",
    "    \n",
    "    print(f\"Successfully processed and stored {len(documents)} advisories!\")\n",
    "    return index, processed_advisories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300f263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
